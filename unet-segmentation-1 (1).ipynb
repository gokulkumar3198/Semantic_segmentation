{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pickle\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms as T\nimport torchvision\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nfrom PIL import Image\nimport cv2\nimport albumentations as albu\n\nimport time\nimport os\nfrom tqdm.notebook import tqdm\n\n# from torchsummary import summary\n# import segmentation_models_pytorch as smp\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"fyBJm6KYqYAK","execution":{"iopub.status.busy":"2022-06-12T20:22:13.089771Z","iopub.execute_input":"2022-06-12T20:22:13.09056Z","iopub.status.idle":"2022-06-12T20:22:17.055602Z","shell.execute_reply.started":"2022-06-12T20:22:13.090438Z","shell.execute_reply":"2022-06-12T20:22:17.054856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"F70Q8xnN5hgD","outputId":"e7faf3d7-103e-47bb-f6d9-61c1f330c7f1","execution":{"iopub.status.busy":"2022-06-07T14:14:15.746417Z","iopub.execute_input":"2022-06-07T14:14:15.746669Z","iopub.status.idle":"2022-06-07T14:14:15.752345Z","shell.execute_reply.started":"2022-06-07T14:14:15.746639Z","shell.execute_reply":"2022-06-07T14:14:15.751649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing","metadata":{"id":"-bdGZY2WqYAR"}},{"cell_type":"code","source":"Train_IMAGE_PATH = '../input/final-datasetbenignetpvmf/Data_Benign+ET+PV+MF/Train/'\nTrain_MASK_PATH = '../input/final-datasetbenignetpvmf/Data_Benign+ET+PV+MF/Train_gt/'","metadata":{"id":"nBGUUDVSqYAU","execution":{"iopub.status.busy":"2022-06-12T20:22:20.981868Z","iopub.execute_input":"2022-06-12T20:22:20.982144Z","iopub.status.idle":"2022-06-12T20:22:20.985521Z","shell.execute_reply.started":"2022-06-12T20:22:20.982097Z","shell.execute_reply":"2022-06-12T20:22:20.984841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_classes = 5 \n\ndef create_df(IMAGE_PATH):\n    name = []\n    for dirname, _, filenames in os.walk(IMAGE_PATH):\n        for filename in filenames:\n            name.append(filename.split('.')[0])\n    \n    return pd.DataFrame({'id': name}, index = np.arange(0, len(name)))\n\ndf = create_df(Train_IMAGE_PATH)\nprint('Total Patches: ', len(df))","metadata":{"id":"PH4dhlpkqYAV","outputId":"cedc7814-fca2-4ab2-ee2b-44950e2a5692","execution":{"iopub.status.busy":"2022-06-12T20:22:23.768658Z","iopub.execute_input":"2022-06-12T20:22:23.769394Z","iopub.status.idle":"2022-06-12T20:22:24.730944Z","shell.execute_reply.started":"2022-06-12T20:22:23.769357Z","shell.execute_reply":"2022-06-12T20:22:24.730176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Val_IMAGE_PATH = \"../input/final-datasetbenignetpvmf/Data_Benign+ET+PV+MF/Validation/\"\nVal_MASK_PATH = \"../input/final-datasetbenignetpvmf/Data_Benign+ET+PV+MF/Validation_gt/\"\n# Test_IMAGE_PATH = \"../input/new-data/val_full-20211130T184212Z-001/val_full/images/\"\n# Test_MASK_PATH = \"../input/new-data/val_full-20211130T184212Z-001/val_full/mask/\"","metadata":{"id":"Tl1yM7haqYAW","execution":{"iopub.status.busy":"2022-06-12T20:22:29.121679Z","iopub.execute_input":"2022-06-12T20:22:29.122213Z","iopub.status.idle":"2022-06-12T20:22:29.126936Z","shell.execute_reply.started":"2022-06-12T20:22:29.122178Z","shell.execute_reply":"2022-06-12T20:22:29.126172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val = create_df(Val_IMAGE_PATH)\nprint('Total Val Images: ', len(df_val))\nprint(df_val)","metadata":{"id":"aHrJkN49qYAX","outputId":"a99c3630-2c8b-4fa6-bf27-1692b2c3da3b","execution":{"iopub.status.busy":"2022-06-12T20:22:32.585453Z","iopub.execute_input":"2022-06-12T20:22:32.58619Z","iopub.status.idle":"2022-06-12T20:22:32.616605Z","shell.execute_reply.started":"2022-06-12T20:22:32.586139Z","shell.execute_reply":"2022-06-12T20:22:32.615922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_val['id'][50])","metadata":{"execution":{"iopub.status.busy":"2022-06-12T20:22:55.13916Z","iopub.execute_input":"2022-06-12T20:22:55.139718Z","iopub.status.idle":"2022-06-12T20:22:55.152436Z","shell.execute_reply.started":"2022-06-12T20:22:55.13968Z","shell.execute_reply":"2022-06-12T20:22:55.148874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_test = create_df(Test_IMAGE_PATH)\n# print('Total Test Images: ', len(df_test))","metadata":{"id":"UQWGfgTvqYAX","execution":{"iopub.status.busy":"2022-06-07T14:14:17.305953Z","iopub.execute_input":"2022-06-07T14:14:17.306641Z","iopub.status.idle":"2022-06-07T14:14:17.311271Z","shell.execute_reply.started":"2022-06-07T14:14:17.306602Z","shell.execute_reply":"2022-06-07T14:14:17.310407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df['id'][50])","metadata":{"id":"VQhx9w3C7Cqk","outputId":"a5e89819-d253-43ab-91a1-32e5107c4e92","execution":{"iopub.status.busy":"2022-06-12T20:22:59.134522Z","iopub.execute_input":"2022-06-12T20:22:59.135043Z","iopub.status.idle":"2022-06-12T20:22:59.140213Z","shell.execute_reply.started":"2022-06-12T20:22:59.135005Z","shell.execute_reply":"2022-06-12T20:22:59.139222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df)","metadata":{"id":"BLcqxm5q6QWH","outputId":"016346c2-569d-473e-a231-84558b694302","execution":{"iopub.status.busy":"2022-06-12T20:23:01.558827Z","iopub.execute_input":"2022-06-12T20:23:01.559349Z","iopub.status.idle":"2022-06-12T20:23:01.565863Z","shell.execute_reply.started":"2022-06-12T20:23:01.559314Z","shell.execute_reply":"2022-06-12T20:23:01.564922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = Image.open(Train_IMAGE_PATH  + df['id'][50] + '.png')\n\nmask = Image.open(Train_MASK_PATH  + df['id'][50] + '_gt.png')\nprint('Image Size', np.asarray(img).shape)\nprint('Mask Size', np.asarray(mask).shape)\n\n\nplt.imshow(img)\nplt.imshow(mask, alpha=0.6)\nplt.title('Picture with Mask Appplied')\nplt.show()","metadata":{"id":"zSIN8mpsqYAZ","outputId":"647938b4-b3fa-4ad8-971c-273992264703","execution":{"iopub.status.busy":"2022-06-12T20:23:05.197147Z","iopub.execute_input":"2022-06-12T20:23:05.197621Z","iopub.status.idle":"2022-06-12T20:23:05.513742Z","shell.execute_reply.started":"2022-06-12T20:23:05.197584Z","shell.execute_reply":"2022-06-12T20:23:05.513048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_map = [[ 0. , 0. , 0.], [0. , 255. , 0.], [255. , 0., 0.] ,[0. , 0. , 255.],[0. , 255. , 255.],[255. , 255. , 0.] ] #Black[0] , Green[1] , Red[2] , Blue[3], Turqoise[4], Yellow[5]","metadata":{"id":"FYCCJ6fSqYAa","execution":{"iopub.status.busy":"2022-06-12T20:24:42.9794Z","iopub.execute_input":"2022-06-12T20:24:42.979948Z","iopub.status.idle":"2022-06-12T20:24:42.985892Z","shell.execute_reply.started":"2022-06-12T20:24:42.979905Z","shell.execute_reply":"2022-06-12T20:24:42.985215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''This method will convert mask labels(to be trained) from RGB to a 2D image whic holds class labels of the pixels.'''\ndef form_2D_label(mask,class_map):\n    # plt.imshow(mask)\n    \n    mask = mask.astype(\"uint8\")\n    label = np.zeros(mask.shape[:2],dtype= np.uint8)\n    \n    for i, rgb in enumerate(class_map):\n        label[(mask == rgb).all(axis=2)] = i\n    \n    return label","metadata":{"id":"Skv-TBj9qYAb","execution":{"iopub.status.busy":"2022-06-12T20:24:47.976886Z","iopub.execute_input":"2022-06-12T20:24:47.97753Z","iopub.status.idle":"2022-06-12T20:24:47.983282Z","shell.execute_reply.started":"2022-06-12T20:24:47.97749Z","shell.execute_reply":"2022-06-12T20:24:47.982378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_count = np.asarray([560201119,  95301323,  29131557 , 29131557, 29131557, 29131557]) #change these pixel counts for six classes\ntot = np.sum(class_count)\n\nclass_weights = (tot - class_count)/tot\nprint(class_weights)\nweights = torch.tensor(list(class_weights)).to(device, dtype = torch.float)","metadata":{"id":"W8_TUzE3qYAc","outputId":"c3985390-530b-49bd-d6d5-879043849abb","execution":{"iopub.status.busy":"2022-06-12T20:25:21.415489Z","iopub.execute_input":"2022-06-12T20:25:21.415811Z","iopub.status.idle":"2022-06-12T20:25:24.60795Z","shell.execute_reply.started":"2022-06-12T20:25:21.415773Z","shell.execute_reply":"2022-06-12T20:25:24.607074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = albu.Compose([\n    albu.HorizontalFlip(p=0.2),\n    albu.VerticalFlip(p=0.2),\n    albu.CropAndPad (percent = -0.2, keep_size=True, interpolation=cv2.INTER_NEAREST, p=0.2),\n    albu.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit= 15, interpolation= cv2.INTER_NEAREST,\n                                          border_mode= cv2.BORDER_REPLICATE, p=0.2)\n])","metadata":{"id":"N5hXpFX3HB6i","execution":{"iopub.status.busy":"2022-06-12T20:25:28.09695Z","iopub.execute_input":"2022-06-12T20:25:28.097744Z","iopub.status.idle":"2022-06-12T20:25:28.103782Z","shell.execute_reply.started":"2022-06-12T20:25:28.097704Z","shell.execute_reply":"2022-06-12T20:25:28.102838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch._C import NoneType\nclass CytoDataset(Dataset):\n    \n    def __init__(self, img_path, mask_path, X , transform=transform):\n        self.img_path = img_path\n        self.mask_path = mask_path\n        self.X = X\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        if self.transform == None:\n            img = cv2.imread(self.img_path  + self.X[idx] + '.png')\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            mask = cv2.imread(self.mask_path  + self.X[idx] + '_gt.png')\n            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n        else:\n            img = cv2.imread(self.img_path  + self.X[idx] + '.png')\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            mask = cv2.imread(self.mask_path  + self.X[idx] + '_gt.png')\n            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n            augmentations = transform(image=img,mask=mask)\n            img = augmentations['image']\n            mask = augmentations['mask']\n        # plt.imshow(mask)\n        mask_2 = form_2D_label(mask, class_map)\n        \n        img = (img - img.min())/(img.max() - img.min())\n        #, T.Normalize(self.mean, self.std)\n        t = T.Compose([T.ToTensor()])\n        img = t(img)\n        mask_2 = torch.from_numpy(mask_2).long()\n        # print(img.shape)\n        # print(mask_2.shape)\n            \n        return img, mask_2","metadata":{"id":"V0upKZKzqYAe","execution":{"iopub.status.busy":"2022-06-12T20:25:32.155769Z","iopub.execute_input":"2022-06-12T20:25:32.156022Z","iopub.status.idle":"2022-06-12T20:25:32.16673Z","shell.execute_reply.started":"2022-06-12T20:25:32.155994Z","shell.execute_reply":"2022-06-12T20:25:32.166073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CytoDataset_val(Dataset):\n    \n    def __init__(self, img_path, mask_path, X , transform=None):\n        self.img_path = img_path\n        self.mask_path = mask_path\n        self.X = X\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        img = cv2.imread(self.img_path  + self.X[idx] + '.png')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(self.mask_path  + self.X[idx] + '_gt.png')\n        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n        # plt.imshow(mask)\n        mask_2 = form_2D_label(mask, class_map)\n        \n        img = (img - img.min())/(img.max() - img.min())\n        #, T.Normalize(self.mean, self.std)\n        t = T.Compose([T.ToTensor()])\n        img = t(img)\n        mask_2 = torch.from_numpy(mask_2).long()\n        # print(img.shape)\n        # print(mask_2.shape)\n            \n        return img, mask_2","metadata":{"execution":{"iopub.status.busy":"2022-06-12T20:25:38.206014Z","iopub.execute_input":"2022-06-12T20:25:38.206719Z","iopub.status.idle":"2022-06-12T20:25:38.215404Z","shell.execute_reply.started":"2022-06-12T20:25:38.206681Z","shell.execute_reply":"2022-06-12T20:25:38.214525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with augmentation\ntrain_set = CytoDataset(Train_IMAGE_PATH, Train_MASK_PATH, df['id'].values)\nval_set = CytoDataset(Val_IMAGE_PATH, Val_MASK_PATH, df_val['id'].values,transform=None)\n#without augmentation\n# train_set = CytoDataset(Train_IMAGE_PATH, Train_MASK_PATH, df['id'].values,transform=None)\n# val_set = CytoDataset(Val_IMAGE_PATH, Val_MASK_PATH, df_val['id'].values,transform=None)\n\n#dataloader\nbatch_size= 1\n\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)  ","metadata":{"id":"2Oe67KOpqYAf","execution":{"iopub.status.busy":"2022-06-12T20:25:46.661009Z","iopub.execute_input":"2022-06-12T20:25:46.661563Z","iopub.status.idle":"2022-06-12T20:25:46.667491Z","shell.execute_reply.started":"2022-06-12T20:25:46.661526Z","shell.execute_reply":"2022-06-12T20:25:46.666648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" print( train_set.__len__())","metadata":{"id":"4y-_GCloqYAf","outputId":"ba9c56b5-f7ac-4b7b-e0c5-fb29b87750e6","execution":{"iopub.status.busy":"2022-06-12T20:25:49.615269Z","iopub.execute_input":"2022-06-12T20:25:49.615671Z","iopub.status.idle":"2022-06-12T20:25:49.623259Z","shell.execute_reply.started":"2022-06-12T20:25:49.615637Z","shell.execute_reply":"2022-06-12T20:25:49.622167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(val_set.__len__())","metadata":{"id":"r0T78lL1Ee6M","outputId":"5b2d1a61-3ab9-4f70-d1b7-5e1aff9d4538","execution":{"iopub.status.busy":"2022-06-12T20:25:52.810703Z","iopub.execute_input":"2022-06-12T20:25:52.811264Z","iopub.status.idle":"2022-06-12T20:25:52.81522Z","shell.execute_reply.started":"2022-06-12T20:25:52.811227Z","shell.execute_reply":"2022-06-12T20:25:52.814446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(val_loader)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T20:25:54.954498Z","iopub.execute_input":"2022-06-12T20:25:54.955063Z","iopub.status.idle":"2022-06-12T20:25:54.959568Z","shell.execute_reply.started":"2022-06-12T20:25:54.955018Z","shell.execute_reply":"2022-06-12T20:25:54.95861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---------------------------------- Unet model --------------------------------------\n\nclass DoubleConv(nn.Module):\n    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\n\nclass Down(nn.Module):\n    \"\"\"Downscaling with maxpool then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels)\n        )\n\n    def forward(self, x):\n        return self.maxpool_conv(x)\n\n\nclass Up(nn.Module):\n    \"\"\"Upscaling then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels, bilinear=True):\n        super().__init__()\n\n        # if bilinear, use the normal convolutions to reduce the number of channels\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        else:\n            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n\n        self.conv = DoubleConv(in_channels, out_channels)\n\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n        # input is CHW\n        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n\n        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n                        diffY // 2, diffY - diffY // 2])\n        # if you have padding issues, see\n        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n        x = torch.cat([x2, x1], dim=1)\n        return self.conv(x)\n\n\nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n\n    def forward(self, x):\n        return self.conv(x)\n\n\nclass UNet(nn.Module):\n    def __init__(self, n_channels, n_classes, bilinear=True):\n        super(UNet, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.bilinear = bilinear\n\n#         self.inc = DoubleConv(n_channels, 16)\n#         self.down1 = Down(16, 32) \n#         self.down2 = Down(32, 64)\n#         self.down3 = Down(64, 128)\n#         self.down4 = Down(128, 128)\n#         self.up1 = Up(256, 64, bilinear)\n#         self.up2 = Up(128, 32, bilinear)\n#         self.up3 = Up(64, 16, bilinear)\n#         self.up4 = Up(32, 16, bilinear)\n#         self.outc = OutConv(16, n_classes)\n        \n        self.inc = DoubleConv(n_channels, 16*4)\n        self.down1 = Down(16*4, 32*4) \n        self.down2 = Down(32*4, 64*4)\n        self.down3 = Down(64*4, 128*4)\n        self.down4 = Down(128*4, 128*4)\n        self.up1 = Up(256*4, 64*4, bilinear)\n        self.up2 = Up(128*4, 32*4, bilinear)\n        self.up3 = Up(64*4, 16*4, bilinear)\n        self.up4 = Up(32*4, 16*4, bilinear)\n        self.outc = OutConv(16*4, n_classes)\n        \n#         self.inc = DoubleConv(n_channels, 16*8)\n#         self.down1 = Down(16*8, 32*8) \n#         self.down2 = Down(32*8, 64*8)\n#         self.down3 = Down(64*8, 128*8)\n#         self.down4 = Down(128*8, 128*8)\n#         self.up1 = Up(256*8, 64*8, bilinear)\n#         self.up2 = Up(128*8, 32*8, bilinear)\n#         self.up3 = Up(64*8, 16*8, bilinear)\n#         self.up4 = Up(32*8, 16*8, bilinear)\n#         self.outc = OutConv(16*8, n_classes)\n\n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n        logits = self.outc(x)\n        return logits","metadata":{"id":"m7Q6qG5CqYAg","execution":{"iopub.status.busy":"2022-06-12T20:31:01.352996Z","iopub.execute_input":"2022-06-12T20:31:01.35358Z","iopub.status.idle":"2022-06-12T20:31:01.376739Z","shell.execute_reply.started":"2022-06-12T20:31:01.353535Z","shell.execute_reply":"2022-06-12T20:31:01.375405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom packaging import version\n\nclass CrossEntropy2d(nn.Module):\n\n    def __init__(self, size_average=True, ignore_label=255):\n        super(CrossEntropy2d, self).__init__()\n        self.size_average = size_average\n        self.ignore_label = ignore_label\n\n    def forward(self, predict, target, weight= None):\n        \"\"\"\n            Args:\n                predict:(n, c, h, w)\n                target:(n, h, w)\n                weight (Tensor, optional): a manual rescaling weight given to each class.\n                                           If given, has to be a Tensor of size \"nclasses\"\n        \"\"\"\n        assert not target.requires_grad\n        assert predict.dim() == 4\n        assert target.dim() == 3\n        assert predict.size(0) == target.size(0), \"{0} vs {1} \".format(predict.size(0), target.size(0))\n        assert predict.size(2) == target.size(1), \"{0} vs {1} \".format(predict.size(2), target.size(1))\n        assert predict.size(3) == target.size(2), \"{0} vs {1} \".format(predict.size(3), target.size(3))\n        n, c, h, w = predict.size()\n        target_mask = (target >= 0) * (target != self.ignore_label)\n        target = target[target_mask]\n        if not target.data.dim():\n            return Variable(torch.zeros(1))\n        predict = predict.transpose(1, 2).transpose(2, 3).contiguous()\n        predict = predict[target_mask.view(n, h, w, 1).repeat(1, 1, 1, c)].view(-1, c)\n        loss = F.cross_entropy(predict, target, weight=weight, size_average=self.size_average)\n        return loss\n\n\nclass BCEWithLogitsLoss2d(nn.Module):\n\n    def __init__(self, size_average=True, ignore_label=255):\n        super(BCEWithLogitsLoss2d, self).__init__()\n        self.size_average = size_average\n        self.ignore_label = ignore_label\n\n    def forward(self, predict, target, weight=None):\n        \"\"\"\n            Args:\n                predict:(n, 1, h, w)\n                target:(n, 1, h, w)\n                weight (Tensor, optional): a manual rescaling weight given to each class.\n                                           If given, has to be a Tensor of size \"nclasses\"\n        \"\"\"\n        assert not target.requires_grad\n        assert predict.dim() == 4\n        assert target.dim() == 4\n        assert predict.size(0) == target.size(0), \"{0} vs {1} \".format(predict.size(0), target.size(0))\n        assert predict.size(2) == target.size(2), \"{0} vs {1} \".format(predict.size(2), target.size(2))\n        assert predict.size(3) == target.size(3), \"{0} vs {1} \".format(predict.size(3), target.size(3))\n        n, c, h, w = predict.size()\n        target_mask = (target >= 0) * (target != self.ignore_label)\n        target = target[target_mask]\n        if not target.data.dim():\n            return Variable(torch.zeros(1))\n        predict = predict[target_mask]\n        loss = F.binary_cross_entropy_with_logits(predict, target, weight=weight, size_average=self.size_average)\n        return loss","metadata":{"id":"MUp8_OKuqYAh","execution":{"iopub.status.busy":"2022-06-12T20:31:02.629059Z","iopub.execute_input":"2022-06-12T20:31:02.629613Z","iopub.status.idle":"2022-06-12T20:31:02.64691Z","shell.execute_reply.started":"2022-06-12T20:31:02.629576Z","shell.execute_reply":"2022-06-12T20:31:02.646242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args = {'IMG_MEAN' : np.array((104.00698793,116.66876762,122.67891434), dtype=np.float32),  #calculate the mean of RGB in real images of train data\n        'MODEL' : 'U_net' , 'BATCH_SIZE' : 1,\n'ITER_SIZE' : 1,  'NUM_WORKERS' : 4, \n'IGNORE_LABEL' : 255 , 'INPUT_SIZE' : '512,512' , 'LEARNING_RATE' : 2.5e-4 , 'MOMENTUM' : 0.9,  'NUM_CLASSES' : 6, \n'NUM_STEPS' : 20000, \n'POWER' : 0.9,\n'RANDOM_SEED' : 1234,\n'SAVE_NUM_IMAGES' : 2,\n'SAVE_PRED_EVERY' : 5000,\n'SNAPSHOT_DIR' : './snapshots/',\n'WEIGHT_DECAY' : 0.0005,\n\n'LEARNING_RATE_D' : 1e-4,\n'LAMBDA_ADV_PRED' : 0.1,\n'PARTIAL_DATA' : None, #0.5,\n\n'SEMI_START' : 5000,\n'LAMBDA_SEMI' : 0.1,\n'MASK_T' : 0.2,\n\n'LAMBDA_SEMI_ADV':0.001,\n'SEMI_START_ADV' : 0,\n'D_REMAIN' : False, 'GPU':True,\n       'RESTORE_FROM' : 'http://vllab1.ucmerced.edu/~whung/adv-semi-seg/resnet101COCO-41f33a49.pth'}","metadata":{"id":"0fVzv-XSqYAi","execution":{"iopub.status.busy":"2022-06-12T20:31:06.608847Z","iopub.execute_input":"2022-06-12T20:31:06.609122Z","iopub.status.idle":"2022-06-12T20:31:06.615625Z","shell.execute_reply.started":"2022-06-12T20:31:06.60908Z","shell.execute_reply":"2022-06-12T20:31:06.614744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    import copy_reg\nexcept:\n    import copyreg as copy_reg","metadata":{"id":"gtPPOc3CqYAj","execution":{"iopub.status.busy":"2022-06-12T20:31:07.736074Z","iopub.execute_input":"2022-06-12T20:31:07.736355Z","iopub.status.idle":"2022-06-12T20:31:07.742565Z","shell.execute_reply.started":"2022-06-12T20:31:07.736325Z","shell.execute_reply":"2022-06-12T20:31:07.741654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pixel_accuracy(output, mask):\n    with torch.no_grad():\n        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n        correct = torch.eq(output, mask).int()\n        accuracy = float(correct.sum()) / float(correct.numel())\n    return accuracy\n\ndef mIoU(pred_mask, mask, smooth=1e-10, n_classes=5):\n    with torch.no_grad():\n        pred_mask = F.softmax(pred_mask, dim=1)\n        pred_mask = torch.argmax(pred_mask, dim=1)\n        pred_mask = pred_mask.contiguous().view(-1)\n        mask = mask.contiguous().view(-1)\n\n        iou_per_class = []\n        for clas in range(0, n_classes): #loop per pixel class\n            true_class = pred_mask == clas\n            true_label = mask == clas\n\n            if true_label.long().sum().item() == 0: #no exist label in this loop\n                iou_per_class.append(np.nan)\n            else:\n                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n                union = torch.logical_or(true_class, true_label).sum().float().item()\n\n                iou = (intersect + smooth) / (union +smooth)\n                iou_per_class.append(iou)\n        return np.nanmean(iou_per_class)\n    \ndef map_thiss(y_pred,class_map):\n    y_pred_rgb = np.zeros((y_pred.shape[0],y_pred.shape[1],y_pred.shape[2],3))\n    for i in range(y_pred.shape[0]):\n        image = np.zeros((y_pred.shape[1],y_pred.shape[2],3))\n        for j in range(y_pred.shape[1]):\n            for k in range(y_pred.shape[2]):\n                image[j,k,:] = class_map[int(y_pred[i][j][k])]\n        y_pred_rgb[i] = image\n    return y_pred_rgb\n\ndef plot_result(img, title):\n    plt.figure(figsize=(12, 6))\n    plt.title(title)\n    plt.imshow(img[0])\n    plt.show()\n    \ndef export_model(model, optimizer=None, name=None, step=None):\n\n        # set output filename\n        if name is not None:\n            out_file = name\n        else:\n            out_file = \"checkpoint\"\n        if step is not None:\n            out_file += \"_step_\" + str(step)\n            \n        out_file = os.path.join(\"./\", out_file + \".pth\")\n\n        # save model\n        data = {\"model_state_dict\": model.state_dict()}\n        if step is not None:\n            data[\"step\"] = step\n        if optimizer is not None:\n            data[\"optimizer_state_dict\"] = optimizer.state_dict()\n        torch.save(data, out_file)","metadata":{"id":"K0tZZ7xaqYAq","execution":{"iopub.status.busy":"2022-06-12T20:31:09.730998Z","iopub.execute_input":"2022-06-12T20:31:09.731542Z","iopub.status.idle":"2022-06-12T20:31:09.748531Z","shell.execute_reply.started":"2022-06-12T20:31:09.731507Z","shell.execute_reply":"2022-06-12T20:31:09.747715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndef loss_calc(pred, label, gpu):\n    \"\"\"\n    This function returns cross entropy loss for semantic segmentation\n    \"\"\"\n    # out shape batch_size x channels x h x w -> batch_size x channels x h x w\n    # label shape h x w x 1 x batch_size  -> batch_size x 1 x h x w\n    label = Variable(label.long()).cuda(device)\n    criterion = CrossEntropy2d().cuda(device)\n\n    return criterion(pred, label)\n\n\ndef lr_poly(base_lr, iter, max_iter, power):\n    return base_lr*((1-float(iter)/max_iter)**(power))\n\n\ndef adjust_learning_rate(optimizer, i_iter):\n    lr = lr_poly(args[\"LEARNING_RATE\"], i_iter, args[\"NUM_STEPS\"], args[\"POWER\"])\n    optimizer.param_groups[0]['lr'] = lr\n    if len(optimizer.param_groups) > 1 :\n        optimizer.param_groups[1]['lr'] = lr * 10\n\ndef adjust_learning_rate_D(optimizer, i_iter):\n    lr = lr_poly(args[\"LEARNING_RATE_D\"], i_iter, args[\"NUM_STEPS\"], args[\"POWER\"])\n    optimizer.param_groups[0]['lr'] = lr\n    if len(optimizer.param_groups) > 1 :\n        optimizer.param_groups[1]['lr'] = lr * 10\n\ndef one_hot(label):\n    label = label.numpy()\n    one_hot = np.zeros((label.shape[0], args[\"NUM_CLASSES\"], label.shape[1], label.shape[2]), dtype=label.dtype)\n    for i in range(args[\"NUM_CLASSES\"]):\n        one_hot[:,i,...] = (label==i)\n    #handle ignore labels\n    return torch.FloatTensor(one_hot)\n\ndef make_D_label(label, ignore_mask):\n    ignore_mask = np.expand_dims(ignore_mask, axis=1)\n    D_label = np.ones(ignore_mask.shape)*label\n    D_label[ignore_mask] = 255\n    D_label = Variable(torch.FloatTensor(D_label)).cuda(device)\n\n    return D_label","metadata":{"id":"x8LRzMUjqYAr","execution":{"iopub.status.busy":"2022-06-12T20:31:11.532088Z","iopub.execute_input":"2022-06-12T20:31:11.532991Z","iopub.status.idle":"2022-06-12T20:31:11.544415Z","shell.execute_reply.started":"2022-06-12T20:31:11.532949Z","shell.execute_reply":"2022-06-12T20:31:11.543638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler, patch=False):\n    torch.cuda.empty_cache()\n    train_losses = []\n    test_losses = []\n    val_iou = []; val_acc = []\n    train_iou = []; train_acc = []\n    lrs = []\n    min_loss = np.inf\n    decrease = 1 ; not_improve=0\n\n    model.to(device)\n    fit_time = time.time()\n    for e in range(epochs):\n        since = time.time()\n        running_loss = 0\n        iou_score = 0\n        accuracy = 0\n        #training loop\n        model.train()\n        for i, data in enumerate(tqdm(train_loader)):\n            #training phase\n            image_tiles, mask_tiles = data\n            # print(image_tiles.shape)\n            # print(mask_tiles.shape)\n            image = image_tiles.to(device, dtype = torch.float); mask = mask_tiles.to(device, dtype= torch.float);\n            #forward\n            output = model(image)\n            loss = loss_calc(output, mask, device)\n            #evaluation metrics\n            iou_score += mIoU(output, mask)\n            accuracy += pixel_accuracy(output, mask)\n            #backward\n            loss.backward()\n            optimizer.step() #update weight          \n            optimizer.zero_grad() #reset gradient\n            \n            #step the learning rate\n            lrs.append(get_lr(optimizer))\n            scheduler.step() \n            \n            running_loss += loss.item()\n            \n        model.eval()\n        test_loss = 0\n        test_accuracy = 0\n        val_iou_score = 0\n        #validation loop\n        with torch.no_grad():\n            for i, data in enumerate(tqdm(val_loader)):\n                #reshape to 9 patches from single image, delete batch size\n                image_tiles, mask_tiles = data\n\n\n                image = image_tiles.to(device, dtype = torch.float); mask = mask_tiles.to(device, dtype = torch.float);\n                output = model(image)\n                #evaluation metrics\n                if(i==1):\n                    output_soft = F.softmax(output, dim=1)\n                    output_num = output_soft.cpu().detach().numpy()\n                    pred_mask = np.argmax(output_num, axis = 1)\n        \n                    y_pred_rgb = map_thiss(pred_mask,class_map)\n                    y_test_rgb = map_thiss(mask,class_map)\n                    plot_result(y_test_rgb,\"Original Masks\")\n                    plot_result(y_pred_rgb,\"Predicted Masks\")\n                val_iou_score +=  mIoU(output, mask)\n                test_accuracy += pixel_accuracy(output, mask)\n                #loss\n                loss = loss_calc(output, mask, device)                                  \n                test_loss += loss.item()\n            \n        #calculatio mean for each batch\n        train_losses.append(running_loss/len(train_loader))\n        test_losses.append(test_loss/len(val_loader))\n\n\n        if min_loss > (test_loss/len(val_loader)):\n            print('Loss Decreasing.. {:.3f} >> {:.3f} '.format(min_loss, (test_loss/len(val_loader))))\n            min_loss = (test_loss/len(val_loader))\n            decrease += 1\n            #if decrease % 5 == 0:\n            print('saving model...')\n            export_model(model, optimizer=optimizer, name=\"final\", step = e)\n            #torch.save(model, 'Unet-Mobilenet_v2_val_loss-{:.3f}.pt'.format(test_loss/len(val_loader)))\n\n\n        if (test_loss/len(val_loader)) > min_loss:\n            not_improve += 1\n            min_loss = (test_loss/len(val_loader))\n            print(f'Loss Not Decrease for {not_improve} time')\n            #if not_improve == 7:\n                #print('Loss not decrease for 7 times, Stop Training')\n                #break\n\n        #iou\n        val_iou.append(val_iou_score/len(val_loader))\n        train_iou.append(iou_score/len(train_loader))\n        train_acc.append(accuracy/len(train_loader))\n        val_acc.append(test_accuracy/ len(val_loader))\n        print(\"Epoch:{}/{}..\".format(e+1, epochs),\n              \"Train Loss: {:.3f}..\".format(running_loss/len(train_loader)),\n              \"Val Loss: {:.3f}..\".format(test_loss/len(val_loader)),\n              \"Train mIoU:{:.3f}..\".format(iou_score/len(train_loader)),\n              \"Val mIoU: {:.3f}..\".format(val_iou_score/len(val_loader)),\n              \"Train Acc:{:.3f}..\".format(accuracy/len(train_loader)),\n              \"Val Acc:{:.3f}..\".format(test_accuracy/len(val_loader)),\n              \"Time: {:.2f}m\".format((time.time()-since)/60))\n        \n    history = {'train_loss' : train_losses, 'val_loss': test_losses,\n               'train_miou' :train_iou, 'val_miou':val_iou,\n               'train_acc' :train_acc, 'val_acc':val_acc,\n               'lrs': lrs}\n    print('Total time: {:.2f} m' .format((time.time()- fit_time)/60))\n    return history","metadata":{"id":"Vd8bgfnxqYAs","execution":{"iopub.status.busy":"2022-06-12T20:31:13.604694Z","iopub.execute_input":"2022-06-12T20:31:13.604985Z","iopub.status.idle":"2022-06-12T20:31:13.628419Z","shell.execute_reply.started":"2022-06-12T20:31:13.604954Z","shell.execute_reply":"2022-06-12T20:31:13.627386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_lr = 1e-3\nepoch = 50\nweight_decay = 1e-4\n\nmodel = UNet(n_classes= 6,\n                 n_channels= 3)\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=weight_decay)\nsched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch,\n                                            steps_per_epoch=len(train_loader))\n\nhistory = fit(epoch, model, train_loader, val_loader, criterion, optimizer, sched)\n# history = fit(epoch, model, val_loader, val_loader, criterion, optimizer, sched)","metadata":{"id":"s8yBQ0M5qYAs","outputId":"1983e162-4413-4148-afd2-fcc61ecd880b","execution":{"iopub.status.busy":"2022-06-12T20:31:15.702843Z","iopub.execute_input":"2022-06-12T20:31:15.703368Z","iopub.status.idle":"2022-06-12T20:31:40.070604Z","shell.execute_reply.started":"2022-06-12T20:31:15.703329Z","shell.execute_reply":"2022-06-12T20:31:40.069311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss(history):\n    plt.plot(history['val_loss'], label='val', marker='o')\n    plt.plot( history['train_loss'], label='train', marker='o')\n    plt.title('Loss per epoch'); plt.ylabel('loss');\n    plt.xlabel('epoch')\n    plt.legend(), plt.grid()\n    plt.show()\n    \ndef plot_score(history):\n    plt.plot(history['train_miou'], label='train_mIoU', marker='*')\n    plt.plot(history['val_miou'], label='val_mIoU',  marker='*')\n    plt.title('Score per epoch'); plt.ylabel('mean IoU')\n    plt.xlabel('epoch')\n    plt.legend(), plt.grid()\n    plt.show()\n    \ndef plot_acc(history):\n    plt.plot(history['train_acc'], label='train_accuracy', marker='*')\n    plt.plot(history['val_acc'], label='val_accuracy',  marker='*')\n    plt.title('Accuracy per epoch'); plt.ylabel('Accuracy')\n    plt.xlabel('epoch')\n    plt.legend(), plt.grid()\n    plt.show()","metadata":{"id":"cDyNgniqqYAs","execution":{"iopub.status.busy":"2022-06-07T14:25:01.83417Z","iopub.status.idle":"2022-06-07T14:25:01.834754Z","shell.execute_reply.started":"2022-06-07T14:25:01.834505Z","shell.execute_reply":"2022-06-07T14:25:01.83453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(history)\nplot_score(history)\nplot_acc(history)","metadata":{"id":"janpK-wTqYAt","execution":{"iopub.status.busy":"2022-06-07T14:25:01.835923Z","iopub.status.idle":"2022-06-07T14:25:01.836452Z","shell.execute_reply.started":"2022-06-07T14:25:01.836229Z","shell.execute_reply":"2022-06-07T14:25:01.836255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('./history.pickle', 'wb') as handle:\n    pickle.dump(history, handle, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"id":"4tfQcRUwqYAt","execution":{"iopub.status.busy":"2022-06-07T14:25:01.837569Z","iopub.status.idle":"2022-06-07T14:25:01.838117Z","shell.execute_reply.started":"2022-06-07T14:25:01.837893Z","shell.execute_reply":"2022-06-07T14:25:01.837918Z"},"trusted":true},"execution_count":null,"outputs":[]}]}